# SOSP 2024 Experiments

This document describes how to run the main experiments in the [SOSP '24](https://sigops.org/s/conferences/sosp/2024/) paper [Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in ML Serving](https://arxiv.org/abs/2312.05385).

## Setup

### Hardware Setup

We have tested Apparate on CPU nodes on Cloudlab. We will provide more instructions on obtaining

### Downloading Data

For ease and speed of reproduction, we provide a simulator that replays request arrival traces on CPUs. The simulator implements all core logic in our system. Alongside the simulator, we also provide picked data of requests in our workloads. Due to the size of these pickle files, we compress them (~435M) and host them on Google Drive and they can be downloaded via utilities like `gdown`.

```bash
mkdir apparate-ae; cd apparate-ae
pip install gdown
# download the tar file
gdown --fuzzy 'https://drive.google.com/file/d/1EN6ciNDBL2dEzSW4qdUTc9t4vOYkzWD8/view?usp=sharing'
# uncompress the tar file
tar -xzvf apparate-data.tar.gz
rm apparate-data.tar.gz
# clone this repo
git clone https://github.com/dywsjtu/apparate-ae.git
```


### Software Dependencies

Prob just use conda?
Python can be installed using [Miniconda](https://docs.conda.io/en/latest/miniconda.html).

Required software dependencies can be installed using:

```bash
apt-get -y install cmake g++ gcc libnuma-dev make numactl zlib1g-dev
pip install -r scheduler/requirements.txt
cd scheduler; make
```

### Sanity Check

Once all the dependencies has been set up, the directory should have the following structure:

```
--apparate-ae
  --apparate-ae (this repo)
  --apparate_latency (this will be populated in the next step for plotting)
  --batch_decisions (downloaded from Google Drive and decompressed)
  --bootstrap_pickles (...)
  --optimal_latency
  --profile_pickles_bs
  --simulation_pickles
```

## Reproducing Experiments

First, cd into the apparate-ae directory: `cd apparate-ae`.

To reproduce the CV main results in Fig. 12 and 13, run `python run_cv.py` (takes ~10-20 minutes on a 32-core CPU). To reproduce the NLP main results in Fig. 14, run `python run_nlp.py` (takes ~xxx minutes on a 32-core CPU).

Aggregate results can be found in output_{cv,nlp}.txt, which are generated by executing the above scripts. The system log, which details how our system performs ramp adjustment and threshold tuning, can be found in `/logs/output_{model_name}_{dataset}.log`.

Running the above scripts will also produce pickle files that contain detailed, per-request latencies in `/apparate_latency`.

## Plotting Results

TODO
